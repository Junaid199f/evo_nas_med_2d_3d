C:\Users\IRMAS\miniconda3\envs\ml\python.exe "D:\Junaid\New Work\GA - Attention - Surrogate - MultiGPU\main_args.py"
Parents_Trained_status:  False
Resume Training Status: False
date and time = 22-03-2023-17-45-11
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
Parents Individual Number # 0


Epoch [1], Loss: 0.7960, Training Accuracy: 67.45%, Validation Accuracy: 69.15%
Epoch [2], Loss: 0.6954, Training Accuracy: 69.81%, Validation Accuracy: 71.07%
Epoch [3], Loss: 0.6266, Training Accuracy: 72.87%, Validation Accuracy: 74.87%
Epoch [4], Loss: 0.5689, Training Accuracy: 75.94%, Validation Accuracy: 76.75%
Epoch [5], Loss: 0.5285, Training Accuracy: 77.80%, Validation Accuracy: 78.37%
Parents Individual Number # 1


Epoch [1], Loss: 0.7356, Training Accuracy: 67.67%, Validation Accuracy: 71.47%
Epoch [2], Loss: 0.5855, Training Accuracy: 74.14%, Validation Accuracy: 76.82%
Epoch [3], Loss: 0.5007, Training Accuracy: 78.56%, Validation Accuracy: 81.74%
Epoch [4], Loss: 0.4364, Training Accuracy: 81.82%, Validation Accuracy: 83.62%
Epoch [5], Loss: 0.3816, Training Accuracy: 84.61%, Validation Accuracy: 85.44%
Parents Individual Number # 2


Epoch [1], Loss: 0.7838, Training Accuracy: 67.15%, Validation Accuracy: 68.69%
Epoch [2], Loss: 0.6925, Training Accuracy: 70.14%, Validation Accuracy: 72.85%
Epoch [3], Loss: 0.6324, Training Accuracy: 72.69%, Validation Accuracy: 75.13%
Epoch [4], Loss: 0.5883, Training Accuracy: 75.11%, Validation Accuracy: 76.59%
Epoch [5], Loss: 0.5476, Training Accuracy: 77.65%, Validation Accuracy: 79.69%
Parents Individual Number # 3


Epoch [1], Loss: 0.7455, Training Accuracy: 67.96%, Validation Accuracy: 69.82%
Epoch [2], Loss: 0.6652, Training Accuracy: 70.61%, Validation Accuracy: 72.82%
Epoch [3], Loss: 0.6034, Training Accuracy: 73.33%, Validation Accuracy: 75.13%
Epoch [4], Loss: 0.5433, Training Accuracy: 76.72%, Validation Accuracy: 78.70%
Epoch [5], Loss: 0.5107, Training Accuracy: 78.28%, Validation Accuracy: 80.85%
Parents Individual Number # 4


Epoch [1], Loss: 0.7626, Training Accuracy: 67.90%, Validation Accuracy: 70.15%
Epoch [2], Loss: 0.6443, Training Accuracy: 72.09%, Validation Accuracy: 73.98%
Epoch [3], Loss: 0.5593, Training Accuracy: 76.14%, Validation Accuracy: 78.57%
Epoch [4], Loss: 0.4957, Training Accuracy: 79.36%, Validation Accuracy: 79.29%
Epoch [5], Loss: 0.4661, Training Accuracy: 80.91%, Validation Accuracy: 81.51%
Parents Individual Number # 5


Epoch [1], Loss: 0.7920, Training Accuracy: 66.91%, Validation Accuracy: 69.65%
Epoch [2], Loss: 0.6963, Training Accuracy: 70.26%, Validation Accuracy: 72.03%
Epoch [3], Loss: 0.6415, Training Accuracy: 72.77%, Validation Accuracy: 73.75%
Epoch [4], Loss: 0.6097, Training Accuracy: 74.47%, Validation Accuracy: 76.25%
Epoch [5], Loss: 0.5734, Training Accuracy: 76.01%, Validation Accuracy: 75.59%
Parents Individual Number # 6


Epoch [1], Loss: 0.7503, Training Accuracy: 68.02%, Validation Accuracy: 70.81%
Epoch [2], Loss: 0.6463, Training Accuracy: 71.69%, Validation Accuracy: 73.45%
Epoch [3], Loss: 0.5703, Training Accuracy: 76.15%, Validation Accuracy: 78.70%
Epoch [4], Loss: 0.5076, Training Accuracy: 79.02%, Validation Accuracy: 81.70%
Epoch [5], Loss: 0.4634, Training Accuracy: 80.97%, Validation Accuracy: 83.78%
Parents Individual Number # 7


Epoch [1], Loss: 0.7128, Training Accuracy: 68.84%, Validation Accuracy: 77.38%
Epoch [2], Loss: 0.5206, Training Accuracy: 78.51%, Validation Accuracy: 80.65%
Epoch [3], Loss: 0.4490, Training Accuracy: 81.93%, Validation Accuracy: 83.03%
Epoch [4], Loss: 0.4007, Training Accuracy: 83.94%, Validation Accuracy: 84.64%
Epoch [5], Loss: 0.3713, Training Accuracy: 85.12%, Validation Accuracy: 84.54%
Parents Individual Number # 8


Epoch [1], Loss: 0.7761, Training Accuracy: 68.19%, Validation Accuracy: 71.00%
Epoch [2], Loss: 0.6655, Training Accuracy: 71.54%, Validation Accuracy: 73.38%
Epoch [3], Loss: 0.6158, Training Accuracy: 73.99%, Validation Accuracy: 75.30%
Epoch [4], Loss: 0.5725, Training Accuracy: 76.23%, Validation Accuracy: 77.77%
Epoch [5], Loss: 0.5384, Training Accuracy: 78.18%, Validation Accuracy: 78.60%
Parents Individual Number # 9


Epoch [1], Loss: 0.6933, Training Accuracy: 69.91%, Validation Accuracy: 77.05%
Epoch [2], Loss: 0.5290, Training Accuracy: 78.03%, Validation Accuracy: 79.85%
Epoch [3], Loss: 0.4594, Training Accuracy: 80.97%, Validation Accuracy: 82.66%
Epoch [4], Loss: 0.4084, Training Accuracy: 83.41%, Validation Accuracy: 85.01%
Epoch [5], Loss: 0.3687, Training Accuracy: 85.00%, Validation Accuracy: 84.48%
Parents Individual Number # 10


Epoch [1], Loss: 0.7485, Training Accuracy: 68.44%, Validation Accuracy: 71.10%
Epoch [2], Loss: 0.6004, Training Accuracy: 74.16%, Validation Accuracy: 78.43%
Epoch [3], Loss: 0.4964, Training Accuracy: 79.49%, Validation Accuracy: 80.98%
Epoch [4], Loss: 0.4267, Training Accuracy: 82.92%, Validation Accuracy: 84.91%
Epoch [5], Loss: 0.3932, Training Accuracy: 84.91%, Validation Accuracy: 86.43%
Parents Individual Number # 11


Epoch [1], Loss: 0.7829, Training Accuracy: 67.36%, Validation Accuracy: 68.66%
Epoch [2], Loss: 0.6702, Training Accuracy: 70.37%, Validation Accuracy: 73.41%
Epoch [3], Loss: 0.5614, Training Accuracy: 76.07%, Validation Accuracy: 79.76%
Epoch [4], Loss: 0.4764, Training Accuracy: 80.73%, Validation Accuracy: 83.42%
Epoch [5], Loss: 0.4167, Training Accuracy: 84.17%, Validation Accuracy: 85.20%
Parents Individual Number # 12


Epoch [1], Loss: 0.7712, Training Accuracy: 65.83%, Validation Accuracy: 70.31%
Epoch [2], Loss: 0.6280, Training Accuracy: 72.91%, Validation Accuracy: 75.73%
Epoch [3], Loss: 0.5173, Training Accuracy: 78.43%, Validation Accuracy: 80.48%
Epoch [4], Loss: 0.4326, Training Accuracy: 82.57%, Validation Accuracy: 83.29%
Epoch [5], Loss: 0.3839, Training Accuracy: 84.93%, Validation Accuracy: 85.73%
Parents Individual Number # 13


Epoch [1], Loss: 0.7299, Training Accuracy: 68.41%, Validation Accuracy: 72.32%
Epoch [2], Loss: 0.5546, Training Accuracy: 76.47%, Validation Accuracy: 79.16%
Epoch [3], Loss: 0.4482, Training Accuracy: 81.89%, Validation Accuracy: 83.19%
Epoch [4], Loss: 0.3878, Training Accuracy: 84.76%, Validation Accuracy: 85.87%
Epoch [5], Loss: 0.3428, Training Accuracy: 86.59%, Validation Accuracy: 87.38%
Parents Individual Number # 14


Epoch [1], Loss: 0.7528, Training Accuracy: 67.77%, Validation Accuracy: 72.49%
Epoch [2], Loss: 0.5805, Training Accuracy: 75.42%, Validation Accuracy: 78.63%
Epoch [3], Loss: 0.4841, Training Accuracy: 80.09%, Validation Accuracy: 82.03%
Epoch [4], Loss: 0.4303, Training Accuracy: 82.76%, Validation Accuracy: 83.62%
Epoch [5], Loss: 0.3880, Training Accuracy: 85.02%, Validation Accuracy: 86.72%
Parents Individual Number # 15


Epoch [1], Loss: 0.7717, Training Accuracy: 67.38%, Validation Accuracy: 69.72%
Epoch [2], Loss: 0.6528, Training Accuracy: 71.99%, Validation Accuracy: 75.03%
Epoch [3], Loss: 0.5673, Training Accuracy: 76.42%, Validation Accuracy: 78.86%
Epoch [4], Loss: 0.5042, Training Accuracy: 79.58%, Validation Accuracy: 80.98%
Epoch [5], Loss: 0.4593, Training Accuracy: 81.72%, Validation Accuracy: 82.50%
Parents Individual Number # 16


Epoch [1], Loss: 0.7771, Training Accuracy: 67.54%, Validation Accuracy: 69.32%
Epoch [2], Loss: 0.6892, Training Accuracy: 68.84%, Validation Accuracy: 71.27%
Epoch [3], Loss: 0.6293, Training Accuracy: 71.95%, Validation Accuracy: 74.50%
Epoch [4], Loss: 0.5803, Training Accuracy: 74.31%, Validation Accuracy: 76.35%
Epoch [5], Loss: 0.5257, Training Accuracy: 77.83%, Validation Accuracy: 79.95%
Parents Individual Number # 17


Epoch [1], Loss: 0.7260, Training Accuracy: 69.56%, Validation Accuracy: 74.80%
Epoch [2], Loss: 0.5483, Training Accuracy: 77.86%, Validation Accuracy: 79.82%
Epoch [3], Loss: 0.4793, Training Accuracy: 80.47%, Validation Accuracy: 81.51%
Epoch [4], Loss: 0.4429, Training Accuracy: 81.99%, Validation Accuracy: 83.12%
Epoch [5], Loss: 0.4035, Training Accuracy: 83.37%, Validation Accuracy: 84.81%
Parents Individual Number # 18


Epoch [1], Loss: 0.7342, Training Accuracy: 68.84%, Validation Accuracy: 73.15%
Epoch [2], Loss: 0.5659, Training Accuracy: 76.16%, Validation Accuracy: 78.47%
Epoch [3], Loss: 0.4645, Training Accuracy: 81.29%, Validation Accuracy: 83.16%
Epoch [4], Loss: 0.4011, Training Accuracy: 84.01%, Validation Accuracy: 85.11%
Epoch [5], Loss: 0.3593, Training Accuracy: 85.69%, Validation Accuracy: 85.63%
Parents Individual Number # 19


Epoch [1], Loss: 0.7610, Training Accuracy: 67.35%, Validation Accuracy: 71.10%
Epoch [2], Loss: 0.6244, Training Accuracy: 72.54%, Validation Accuracy: 75.66%
Epoch [3], Loss: 0.5476, Training Accuracy: 76.63%, Validation Accuracy: 78.57%
Epoch [4], Loss: 0.5033, Training Accuracy: 79.05%, Validation Accuracy: 80.09%
Epoch [5], Loss: 0.4653, Training Accuracy: 80.45%, Validation Accuracy: 82.17%
[[0.9, 0, 2, 0.29, 0, 2, 0.72, 1, 3, 0.46, 0, 2, 0.6, 2, 1, 0.78, 2, 5, 0.53, 3, 1, 0.96, 0, 1, 0.29, 0, 1, 0.37, 0, 3, 0.67, 0, 1, 0.54, 0, 3, 0.07, 1, 5, 0.35, 1, 0, 0.06, 3, 0, 0.99, 2, 3], [0.09, 0, 3, 0.59, 0, 3, 0.36, 0, 4, 0.38, 0, 0, 0.75, 1, 3, 0.46, 2, 1, 0.15, 0, 5, 0.93, 1, 3, 0.23, 0, 0, 0.79, 0, 5, 0.94, 1, 5, 0.95, 0, 1, 0.33, 2, 5, 0.52, 0, 2, 0.34, 1, 4, 0.46, 2, 0], [0.36, 0, 2, 0.85, 0, 5, 0.95, 1, 3, 0.25, 1, 1, 0.61, 0, 2, 0.58, 1, 5, 0.84, 3, 3, 0.05, 1, 5, 0.3, 0, 2, 0.35, 0, 4, 0.98, 0, 3, 0.57, 0, 5, 0.02, 2, 4, 0.3, 0, 3, 0.82, 1, 4, 0.42, 2, 4], [0.32, 0, 1, 0.68, 0, 5, 0.17, 0, 3, 0.93, 1, 2, 0.13, 2, 5, 0.27, 0, 5, 0.25, 3, 4, 0.63, 1, 5, 0.76, 0, 2, 0.6, 0, 2, 0.58, 1, 2, 0.12, 1, 1, 0.98, 0, 4, 0.01, 0, 4, 0.32, 2, 5, 0.99, 2, 4], [0.29, 0, 1, 0.62, 0, 2, 0.8, 1, 0, 0.54, 1, 4, 0.61, 2, 4, 0.14, 2, 3, 0.62, 3, 0, 0.37, 2, 1, 0.29, 0, 3, 0.97, 0, 5, 0.49, 1, 4, 0.09, 0, 4, 0.77, 1, 2, 0.52, 2, 3, 0.27, 3, 4, 0.03, 0, 1], [0.69, 0, 1, 0.52, 0, 5, 0.69, 1, 2, 0.81, 0, 3, 0.91, 0, 2, 0.47, 2, 4, 0.68, 2, 1, 0.79, 2, 2, 0.95, 0, 2, 0.37, 0, 2, 0.75, 0, 1, 0.54, 0, 3, 0.59, 2, 3, 0.51, 2, 0, 0.74, 0, 3, 0.86, 2, 5], [0.53, 0, 4, 0.33, 0, 0, 0.26, 1, 2, 0.3, 1, 0, 0.81, 1, 2, 0.1, 1, 3, 0.94, 2, 3, 0.39, 3, 4, 0.92, 0, 2, 0.88, 0, 2, 0.03, 1, 4, 0.46, 0, 3, 0.8, 2, 0, 0.75, 2, 0, 0.36, 2, 5, 0.75, 0, 2], [0.93, 0, 0, 0.31, 0, 3, 0.31, 0, 5, 0.7, 0, 1, 0.36, 2, 3, 0.31, 0, 3, 0.26, 2, 2, 0.73, 2, 1, 0.09, 0, 0, 0.77, 0, 5, 0.99, 0, 1, 0.54, 1, 1, 0.97, 1, 3, 0.12, 0, 2, 0.06, 3, 2, 0.15, 0, 1], [0.7, 0, 4, 0.9, 0, 3, 0.32, 1, 4, 0.05, 1, 5, 0.71, 2, 5, 0.9, 2, 0, 0.9, 0, 4, 0.36, 0, 3, 0.59, 0, 2, 0.11, 0, 0, 0.91, 1, 4, 0.1, 1, 3, 0.59, 2, 0, 0.17, 1, 4, 0.66, 2, 5, 0.43, 0, 2], [0.22, 0, 1, 0.53, 0, 5, 0.24, 0, 5, 0.36, 0, 5, 0.89, 1, 4, 0.97, 0, 3, 0.87, 0, 4, 0.59, 1, 3, 0.69, 0, 1, 0.77, 0, 1, 0.96, 1, 2, 0.09, 0, 0, 0.42, 2, 0, 0.72, 1, 5, 0.36, 2, 5, 0.25, 3, 0], [0.42, 0, 4, 0.73, 0, 2, 0.85, 0, 0, 0.25, 1, 1, 0.62, 1, 1, 0.57, 1, 1, 0.31, 1, 4, 0.69, 3, 2, 0.33, 0, 5, 0.23, 0, 4, 0.85, 1, 4, 0.79, 0, 2, 0.63, 2, 0, 0.65, 2, 1, 0.23, 1, 4, 0.76, 0, 3], [0.28, 0, 2, 0.58, 0, 1, 0.52, 1, 4, 0.9, 0, 1, 0.52, 0, 1, 0.43, 1, 2, 0.1, 2, 2, 0.7, 0, 3, 0.58, 0, 1, 0.71, 0, 3, 0.79, 0, 4, 0.9, 1, 1, 0.82, 0, 4, 0.6, 1, 0, 0.29, 2, 1, 0.7, 3, 2], [0.36, 0, 0, 0.11, 0, 4, 0.7, 1, 0, 0.61, 0, 0, 0.68, 1, 0, 0.94, 1, 4, 0.62, 3, 5, 0.17, 1, 1, 0.94, 0, 5, 0.44, 0, 4, 0.22, 1, 3, 0.37, 1, 3, 0.62, 0, 5, 0.93, 0, 3, 0.28, 2, 3, 0.08, 2, 1], [0.75, 0, 4, 0.9, 0, 2, 0.23, 0, 2, 0.22, 0, 2, 0.58, 2, 1, 0.56, 0, 5, 0.26, 2, 3, 0.41, 2, 0, 0.64, 0, 2, 0.75, 0, 3, 0.09, 1, 1, 0.48, 0, 5, 0.95, 1, 0, 0.6, 0, 4, 0.93, 0, 5, 0.61, 1, 5], [0.06, 0, 2, 0.35, 0, 5, 0.88, 1, 4, 0.17, 1, 3, 0.21, 1, 2, 0.31, 1, 2, 0.23, 2, 0, 0.35, 1, 2, 0.49, 0, 5, 0.89, 0, 3, 0.47, 0, 3, 0.46, 1, 0, 0.51, 0, 4, 0.89, 1, 3, 0.62, 0, 3, 0.95, 3, 0], [0.11, 0, 4, 0.83, 0, 5, 0.45, 0, 4, 0.75, 1, 2, 0.9, 2, 2, 0.78, 0, 5, 0.86, 2, 3, 0.78, 1, 4, 0.47, 0, 0, 0.98, 0, 1, 0.83, 0, 4, 0.12, 0, 0, 0.41, 0, 2, 0.78, 0, 3, 0.94, 1, 3, 0.77, 1, 2], [0.59, 0, 1, 0.52, 0, 3, 0.51, 0, 2, 0.32, 1, 0, 0.57, 0, 0, 0.28, 0, 5, 0.67, 0, 2, 0.14, 1, 3, 0.85, 0, 0, 0.53, 0, 3, 0.46, 0, 3, 0.65, 0, 4, 0.24, 0, 0, 0.9, 1, 3, 0.2, 0, 4, 0.55, 2, 2], [0.57, 0, 2, 0.83, 0, 3, 0.92, 1, 3, 0.82, 1, 2, 0.82, 2, 4, 0.29, 0, 2, 0.49, 1, 4, 0.82, 1, 0, 0.3, 0, 0, 0.06, 0, 4, 0.77, 1, 5, 0.5, 0, 3, 0.49, 0, 3, 0.36, 0, 1, 0.28, 0, 4, 0.12, 0, 5], [0.57, 0, 1, 0.83, 0, 4, 0.97, 1, 3, 0.44, 0, 4, 0.06, 1, 3, 0.26, 0, 3, 0.43, 3, 3, 0.34, 3, 2, 0.76, 0, 2, 0.7, 0, 5, 0.47, 1, 5, 0.8, 0, 3, 0.78, 2, 5, 0.99, 0, 4, 0.59, 0, 0, 0.94, 3, 0], [0.42, 0, 4, 0.7, 0, 1, 0.48, 1, 2, 0.16, 1, 2, 0.22, 2, 4, 0.42, 0, 1, 0.8, 1, 5, 0.59, 3, 2, 0.31, 0, 0, 0.98, 0, 5, 0.66, 0, 3, 0.1, 0, 1, 0.26, 1, 1, 0.86, 1, 2, 0.97, 1, 1, 0.29, 2, 5]]
[21.63143989 14.56406869 20.31043593 19.15455746 18.49405548 24.40554822
 16.21532365 15.45574637 21.4002642  15.52179657 13.57331572 14.79524439
 14.2668428  12.61558785 13.27608983 17.50330251 20.04623514 15.19154557
 14.3659181  17.8335535 ]
Fitting 3 folds for each of 200 candidates, totalling 600 fits
Model with rank: 1
Mean validation score: -0.846 (std: 0.664)
Parameters: {'colsample_bytree': 0.7368330668988126, 'gamma': 0.4382220379376469, 'learning_rate': 0.22287766908427598, 'max_depth': 3, 'n_estimators': 101, 'subsample': 0.9642496014161216}

fitness [21.63143989 14.56406869 20.31043593 19.15455746 18.49405548 24.40554822
 16.21532365 15.45574637 21.4002642  15.52179657 13.57331572 14.79524439
 14.2668428  12.61558785 13.27608983 17.50330251 20.04623514 15.19154557
 14.3659181  17.8335535 ]
Generation Number # 0


In crossover
0.7689099383126826
0.9
yes
yes
48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
Epoch [1], Loss: 0.7212, Training Accuracy: 69.70%, Validation Accuracy: 73.98%
Epoch [2], Loss: 0.5605, Training Accuracy: 75.72%, Validation Accuracy: 79.92%
Epoch [3], Loss: 0.4647, Training Accuracy: 81.06%, Validation Accuracy: 84.11%
Epoch [4], Loss: 0.4029, Training Accuracy: 83.41%, Validation Accuracy: 85.07%
Epoch [5], Loss: 0.3575, Training Accuracy: 85.95%, Validation Accuracy: 87.09%
Epoch [1], Loss: 0.7600, Training Accuracy: 67.33%, Validation Accuracy: 71.40%
Epoch [2], Loss: 0.6142, Training Accuracy: 73.61%, Validation Accuracy: 77.54%
Epoch [3], Loss: 0.5496, Training Accuracy: 76.94%, Validation Accuracy: 79.33%
Epoch [4], Loss: 0.4858, Training Accuracy: 80.26%, Validation Accuracy: 82.03%
Epoch [5], Loss: 0.4533, Training Accuracy: 81.65%, Validation Accuracy: 82.40%
Gbest is  12.615587846763546
fITNESS OFFSPRING IS 12.912813738441216
Generation Number # 1


48 48 16
48 64 32
64 128 64
48 48 16
48 64 32
64 128 64
Epoch [1], Loss: 0.6971, Training Accuracy: 71.27%, Validation Accuracy: 78.14%
Epoch [2], Loss: 0.5207, Training Accuracy: 78.59%, Validation Accuracy: 80.28%
Epoch [3], Loss: 0.4553, Training Accuracy: 81.40%, Validation Accuracy: 82.76%
Epoch [4], Loss: 0.4074, Training Accuracy: 83.31%, Validation Accuracy: 84.02%
Epoch [5], Loss: 0.3852, Training Accuracy: 84.12%, Validation Accuracy: 84.15%
Epoch [1], Loss: 0.7417, Training Accuracy: 68.13%, Validation Accuracy: 71.70%
Epoch [2], Loss: 0.6157, Training Accuracy: 72.44%, Validation Accuracy: 75.79%
Epoch [3], Loss: 0.5280, Training Accuracy: 77.54%, Validation Accuracy: 80.38%
Epoch [4], Loss: 0.4501, Training Accuracy: 81.58%, Validation Accuracy: 84.05%
Epoch [5], Loss: 0.3905, Training Accuracy: 84.99%, Validation Accuracy: 86.26%
Gbest is  12.615587846763546
fITNESS OFFSPRING IS 12.912813738441216
Best Individual is with fitness value::  12.615587846763546

 Individual is
 [0.75, 0, 4, 0.9, 0, 2, 0.23, 0, 2, 0.22, 0, 2, 0.58, 2, 1, 0.56, 0, 5, 0.26, 2, 3, 0.41, 2, 0, 0.64, 0, 2, 0.75, 0, 3, 0.09, 1, 1, 0.48, 0, 5, 0.95, 1, 0, 0.6, 0, 4, 0.93, 0, 5, 0.61, 1, 5]
48 48 16
48 64 32
64 128 64
Epoch [1], Loss: 0.7400, Training Accuracy: 67.82%, Validation Accuracy: 72.59%
Epoch [2], Loss: 0.5830, Training Accuracy: 74.41%, Validation Accuracy: 78.63%
Epoch [3], Loss: 0.4684, Training Accuracy: 80.64%, Validation Accuracy: 83.72%
Epoch [4], Loss: 0.3839, Training Accuracy: 85.30%, Validation Accuracy: 86.23%
Epoch [5], Loss: 0.3353, Training Accuracy: 86.82%, Validation Accuracy: 87.09%
Epoch [6], Loss: 0.3075, Training Accuracy: 88.48%, Validation Accuracy: 88.57%
Epoch [7], Loss: 0.2878, Training Accuracy: 89.22%, Validation Accuracy: 88.84%
Epoch [8], Loss: 0.2871, Training Accuracy: 89.53%, Validation Accuracy: 88.71%
Epoch [9], Loss: 0.2862, Training Accuracy: 89.64%, Validation Accuracy: 87.38%
Epoch [10], Loss: 0.2780, Training Accuracy: 89.81%, Validation Accuracy: 89.46%
Epoch [11], Loss: 0.2769, Training Accuracy: 89.62%, Validation Accuracy: 88.97%
Epoch [12], Loss: 0.2667, Training Accuracy: 90.50%, Validation Accuracy: 89.04%
Epoch [13], Loss: 0.2789, Training Accuracy: 89.71%, Validation Accuracy: 88.90%
Epoch [14], Loss: 0.2769, Training Accuracy: 89.87%, Validation Accuracy: 88.24%
Epoch [15], Loss: 0.2681, Training Accuracy: 90.07%, Validation Accuracy: 89.70%
Epoch [16], Loss: 0.2727, Training Accuracy: 90.01%, Validation Accuracy: 89.40%
Epoch [17], Loss: 0.2736, Training Accuracy: 89.77%, Validation Accuracy: 88.87%
Traceback (most recent call last):
  File "D:\Junaid\New Work\GA - Attention - Surrogate - MultiGPU\main_args.py", line 88, in <module>
    ga.evolve()
  File "D:\Junaid\New Work\GA - Attention - Surrogate - MultiGPU\ga.py", line 266, in evolve
    self.evalate_single_model(self.pop.individuals[min_list_par])
  File "D:\Junaid\New Work\GA - Attention - Surrogate - MultiGPU\ga.py", line 271, in evalate_single_model
    loss = self.evaluator.train(network, 600, hash_indv)
  File "D:\Junaid\New Work\GA - Attention - Surrogate - MultiGPU\evaluate.py", line 69, in train
    outputs,x = model(inputs)
  File "C:\Users\IRMAS\miniconda3\envs\ml\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Junaid\New Work\GA - Attention - Surrogate - MultiGPU\model.py", line 221, in forward
    s0, s1 = s1, cell(s0, s1, self.drop_path_prob)
  File "C:\Users\IRMAS\miniconda3\envs\ml\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Junaid\New Work\GA - Attention - Surrogate - MultiGPU\model.py", line 108, in forward
    h2 = at2(h2)
  File "C:\Users\IRMAS\miniconda3\envs\ml\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Junaid\New Work\GA - Attention - Surrogate - MultiGPU\attentions.py", line 281, in forward
    return x * self._mask(x)
  File "C:\Users\IRMAS\miniconda3\envs\ml\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Junaid\New Work\GA - Attention - Surrogate - MultiGPU\attentions.py", line 268, in forward
    c_weight = self.ChannelAttention(x)
  File "C:\Users\IRMAS\miniconda3\envs\ml\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Junaid\New Work\GA - Attention - Surrogate - MultiGPU\attentions.py", line 218, in forward
    channel_att_raw = self.mlp(max_pool)
  File "C:\Users\IRMAS\miniconda3\envs\ml\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\IRMAS\miniconda3\envs\ml\lib\site-packages\torch\nn\modules\container.py", line 217, in forward
    input = module(input)
  File "C:\Users\IRMAS\miniconda3\envs\ml\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\IRMAS\miniconda3\envs\ml\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


Process finished with exit code 1
